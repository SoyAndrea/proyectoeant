anti_join(mã)
ã <- filter(padres_token, word == "ã")
padres_token <- padres_token %>%
anti_join(ã)
â <- filter(padres_token, word == "â")
padres_token <- padres_token %>%
anti_join(â)
estã <- filter(padres_token, word == "estã")
padres_token <- padres_token %>%
anti_join(estã)
padres_token %>%
count(word, sort = TRUE)
padres_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
Trotta <- read.csv("Trotta.csv")
trotta_texto <- unique(Trotta$text)
trotta_texto <- trotta_texto %>% as.data.frame() %>% rename(word=".")
trotta_token <- trotta_texto %>%
unnest_tokens(word, word)
trotta_token <- trotta_token %>%
anti_join(custom_stop_words)
https2 <- filter(trotta_token, word == "https")
trotta_token <- usuarios_token %>%
anti_join(https)
M<-trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 3)
M
2755 <- filter(trotta_token, word == "2755")
"2755" <- filter(trotta_token, word == "2755")
trotta_token <- usuarios_token %>%
anti_join(2755)
trotta_token %>%
count(word, sort=T)
M<-trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
M
M<-trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 1)
M
trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 1.5)
padres_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 1.5)
#Wordcloud
usuarios_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
usuarios_token <- usuarios_token %>%
anti_join(custom_stop_words)
https <- filter(usuarios_token, word == "https")
tco <- filter(usuarios_token, word == "t.co")
u <- filter(usuarios_token, word == "u")
n <- filter(usuarios_token, word == "n")
fe0f <- filter(usuarios_token, word == "fe0f")
usuarios_token <- usuarios_token %>%
anti_join(https)
usuarios_token <- usuarios_token %>%
anti_join(tco)
usuarios_token <- usuarios_token %>%
anti_join(u)
usuarios_token <- usuarios_token %>%
anti_join(n)
usuarios_token <- usuarios_token %>%
anti_join(fe0f)
usuarios_token %>%
count(word, sort = TRUE)
usuarios_token <- usuarios_token %>%
anti_join(custom_stop_words)
ttps <- filter(usuarios_token, word == "https")
tco <- filter(usuarios_token, word == "t.co")
u <- filter(usuarios_token, word == "u")
n <- filter(usuarios_token, word == "n")
fe0f <- filter(usuarios_token, word == "fe0f")
as  <- filter(usuarios_token, word == "as")
dã  <- filter(usuarios_token, word == "dã")
s  <- filter(usuarios_token, word == "s")
usuarios_token <- usuarios_token %>%
anti_join(https)
usuarios_token <- usuarios_token %>%
anti_join(tco)
usuarios_token <- usuarios_token %>%
anti_join(u)
usuarios_token <- usuarios_token %>%
anti_join(n)
usuarios_token <- usuarios_token %>%
anti_join(fe0f)
usuarios_token <- usuarios_token %>%
anti_join(as)
usuarios_token <- usuarios_token %>%
anti_join(dã)
usuarios_token <- usuarios_token %>%
anti_join(s)
usuarios_token %>%
count(word, sort = TRUE)
usuarios_token %>%
count(word, sort = TRUE) %>%
filter(n > 4) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
scale_fill_manual(values = c( "#414487"))  +
labs(
title= "Frecuencia de palabras de usuarios más retwiteados",
subtitle = "Período del 9 al 16 de junio en Buenos Aireso",
x = "Palabras",
y = "Cantidad") +
coord_flip()
View(PadresOJunio)
View(Padres16junio)
usuarios_RT <- read.csv("Usuarios_RT.csv", encoding = "UTF-8")
Usuarios_texto <- unique(usuarios_RT$text)
Usuarios_texto <- Usuarios_texto %>% as.data.frame() %>% rename(word=".")
custom_stop_words <- tm::stopwords("spanish")
custom_stop_words <- custom_stop_words %>% as.data.frame() %>% rename(word=".")
usuarios_RT <- read.csv("Usuarios_RT.csv", encoding = "UTF-8")
#Librerias de trabajo
library(rtweet)
library(tidyverse)
library(data.table)
library(tm)
library(tidytext)
library(ggplot2)
library(plotly)
library(wordcloud2)
library(wordcloud)
library(RColorBrewer)
library(kableExtra)
devtools::install_github("gaospecial/wordcloud2")
usuarios_RT <- read.csv("Usuarios_RT.csv", encoding = "UTF-8")
Usuarios_texto <- unique(usuarios_RT$text)
Usuarios_texto <- Usuarios_texto %>% as.data.frame() %>% rename(word=".")
custom_stop_words <- tm::stopwords("spanish")
custom_stop_words <- custom_stop_words %>% as.data.frame() %>% rename(word=".")
usuarios_token <- Usuarios_texto %>%
unnest_tokens(word, word)
usuarios_token <- usuarios_token %>%
anti_join(custom_stop_words)
usuarios_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
https <- filter(usuarios_token, word == "https")
tco <- filter(usuarios_token, word == "t.co")
u <- filter(usuarios_token, word == "u")
n <- filter(usuarios_token, word == "n")
fe0f <- filter(usuarios_token, word == "fe0f")
as  <- filter(usuarios_token, word == "as")
dã  <- filter(usuarios_token, word == "dã")
s  <- filter(usuarios_token, word == "s")
usuarios_token <- usuarios_token %>%
anti_join(https)
usuarios_token <- usuarios_token %>%
anti_join(tco)
usuarios_token <- usuarios_token %>%
anti_join(u)
usuarios_token <- usuarios_token %>%
anti_join(n)
usuarios_token <- usuarios_token %>%
anti_join(fe0f)
usuarios_token <- usuarios_token %>%
anti_join(as)
usuarios_token <- usuarios_token %>%
anti_join(dã)
usuarios_token <- usuarios_token %>%
anti_join(s)
#Wordcloud
usuarios_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
View(usuarios_RT)
usuarios_RT <- read.csv("Usuarios_RT.csv", encoding = "UTF-8")
View(usuarios_RT)
usuarios_RT <- read.csv("Usuarios_RT.csv", encoding = "UTF-8")
View(usuarios_RT)
usuarios_RT <- readr::read.csv("Usuarios_RT.csv")
usuarios_RT <- read.csv("Usuarios_RT.csv", fileEncoding = "UTF-8")
View(usuarios_RT)
gc()
usuarios_RT <- read.csv("Usuarios_RT.csv", encoding = "UTF-8")
usuarios_RT <- readr::read_csv("Usuarios_RT.csv", encoding = "UTF-8")
usuarios_RT <- readr::read_csv("Usuarios_RT.csv")
Emoji1 <- filter(usuarios_token, word == "<U+2755>")
usuarios_token <- usuarios_token %>%
anti_join(Emoji1)
#Wordcloud
usuarios_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
#Vamos a hacer un análisis cuantitativo de nuestro corpus. Para eso, contaremos la cantidad de usuarios que hablaron sobre escuelas y aulas.
# usuarios <- usuarios_unicos %>% filter(duplicated(user_id) == FALSE)
#
# #Vamos a ver los usuarios con más rt
# usuarios_RT <- usuarios_unicos[usuarios_unicos$is_retweet == "TRUE", ]
#De esos 3004 usuarios, 1311 fueron RTwitteados
#Vamos a trabajar con el dataset Usuarios_RT, es decir, con los usuarios que fueron retuiteados. A ese DS le saqué todas las columnas y me quedé solo con la de texto, al hacer esto, solo quedaron 64 observaciones.
usuarios_RT <- readr::read_csv("Usuarios_RT.csv")
Usuarios_texto <- unique(usuarios_RT$text)
Usuarios_texto <- Usuarios_texto %>% as.data.frame() %>% rename(word=".")
custom_stop_words <- tm::stopwords("spanish")
custom_stop_words <- custom_stop_words %>% as.data.frame() %>% rename(word=".")
#Token
usuarios_token <- Usuarios_texto %>%
unnest_tokens(word, word)
usuarios_token <- usuarios_token %>%
anti_join(custom_stop_words)
https <- filter(usuarios_token, word == "https")
tco <- filter(usuarios_token, word == "t.co")
u <- filter(usuarios_token, word == "u")
n <- filter(usuarios_token, word == "n")
fe0f <- filter(usuarios_token, word == "fe0f")
as  <- filter(usuarios_token, word == "as")
dã  <- filter(usuarios_token, word == "dã")
s  <- filter(usuarios_token, word == "s")
Emoji1 <- filter(usuarios_token, word == "<U+2755>")
usuarios_token <- usuarios_token %>%
anti_join(https)
usuarios_token <- usuarios_token %>%
anti_join(tco)
usuarios_token <- usuarios_token %>%
anti_join(u)
usuarios_token <- usuarios_token %>%
anti_join(n)
usuarios_token <- usuarios_token %>%
anti_join(fe0f)
usuarios_token <- usuarios_token %>%
anti_join(as)
usuarios_token <- usuarios_token %>%
anti_join(dã)
usuarios_token <- usuarios_token %>%
anti_join(s)
usuarios_token <- usuarios_token %>%
anti_join(Emoji1)
#Wordcloud
usuarios_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
Num1 <- filter(usuarios_token, word == "2755")
usuarios_token <- usuarios_token %>%
anti_join(Num1)
#Wordcloud
usuarios_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
Num2 <- filter(usuarios_token, word == "0001f4cc")
usuarios_token <- usuarios_token %>%
anti_join(Num1, Num2)
usuarios_token <- usuarios_token %>%
anti_join(Num2)
#Wordcloud
usuarios_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
usuarios_token %>%
count(word, sort = TRUE) %>%
filter(n > 4) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
scale_fill_manual(values = c( "#414487"))  +
labs(
title= "Frecuencia de palabras de usuarios más retwiteados",
subtitle = "Período del 9 al 16 de junio en Buenos Aireso",
x = "Palabras",
y = "Cantidad") +
coord_flip()
trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 1.5)
trotta_texto <- unique(Trotta$text)
trotta_texto <- trotta_texto %>% as.data.frame() %>% rename(word=".")
trotta_token <- trotta_texto %>%
unnest_tokens(word, word)
trotta_token <- trotta_token %>%
anti_join(custom_stop_words)
https2 <- filter(trotta_token, word == "https")
trotta_token <- trotta_token %>%
anti_join(https)
Num1 <- filter(trotta_token, word == "2755")
trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 1.5)
Trotta <- read.csv("Trotta.csv", encoding = "UTF-8")
trotta_texto <- unique(Trotta$text)
trotta_texto <- trotta_texto %>% as.data.frame() %>% rename(word=".")
trotta_token <- trotta_texto %>%
unnest_tokens(word, word)
trotta_token <- trotta_token %>%
anti_join(custom_stop_words)
https2 <- filter(trotta_token, word == "https")
trotta_token <- trotta_token %>%
anti_join(https)
Num1 <- filter(trotta_token, word == "2755")
trotta_token <- trotta_token %>%
anti_join(Num1)
trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 1.5)
U <- Filter(trotta_token, word== "u")
U <- filter(trotta_token, word== "U")
trotta_token <- trotta_token %>%
anti_join(U)
trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 1.5)
U <- filter(trotta_token, word== "U" & "u")
u <- filter(trotta_token, word== "U")
trotta_token <- trotta_token %>%
anti_join(u)
trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
u <- filter(trotta_token, word== "U")
trotta_token <- trotta_token %>%
anti_join(u)
trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
#Vamos a hacer una nube de palabras con el time line del ministro Trotta. Para eso, vamos a tokenizar el texto.
Trotta <- read.csv("Trotta.csv", encoding = "UTF-8")
trotta_texto <- unique(Trotta$text)
trotta_texto <- trotta_texto %>% as.data.frame() %>% rename(word=".")
trotta_token <- trotta_texto %>%
unnest_tokens(word, word)
trotta_token <- trotta_token %>%
anti_join(custom_stop_words)
https2 <- filter(trotta_token, word == "https")
trotta_token <- trotta_token %>%
anti_join(https)
Num1 <- filter(trotta_token, word == "2755")
trotta_token <- trotta_token %>%
anti_join(Num1)
U <- filter(trotta_token, word== "U")
trotta_token <- trotta_token %>%
anti_join(U)
u <- filter(trotta_token, word== "U")
trotta_token <- trotta_token %>%
anti_join(u)
#Num2 <- filter(usuarios_token, word == "0001f4cc")
trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
U <- filter(trotta_token, word== "U")
trotta_token <- trotta_token %>%
anti_join(U)
u <- filter(trotta_token, word== "U")
trotta_token <- trotta_token %>%
anti_join(u)
trotta_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 2)
padres_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 1.5)
#Ahora vamos a hacer el mismo procedmiento pero para el time line de la cuenta principal de Padres Organizados.
Padres <- read.csv("Padres.csv", encoding = "UTF-8")
padres_texto <- unique(Padres$text)
padres_texto <- padres_texto %>% as.data.frame() %>% rename(word=".")
padres_token <- padres_texto %>%
unnest_tokens(word, word)
padres_token <- padres_token %>%
anti_join(custom_stop_words)
tco2 <- filter(padres_token, word == "t.co")
padres_token <- padres_token %>%
anti_join(tco2)
https3 <- filter(padres_token, word == "https")
padres_token <- padres_token %>%
anti_join(https3)
u <- filter(padres_token, word == "u")
n <- filter(padres_token, word == "n")
fe0f <- filter(padres_token, word == "fe0f")
padres_token <- padres_token %>%
anti_join(u)
padres_token <- padres_token %>%
anti_join(n)
padres_token <- padres_token %>%
anti_join(fe0f)
s <- filter(padres_token, word == "s")
padres_token <- padres_token %>%
anti_join(s)
niã <- filter(padres_token, word == "niã")
padres_token <- padres_token %>%
anti_join(niã)
mã <- filter(padres_token, word == "mã")
padres_token <- padres_token %>%
anti_join(mã)
ã <- filter(padres_token, word == "ã")
padres_token <- padres_token %>%
anti_join(ã)
â <- filter(padres_token, word == "â")
padres_token <- padres_token %>%
anti_join(â)
estã <- filter(padres_token, word == "estã")
padres_token <- padres_token %>%
anti_join(estã)
padres_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 1.5)
View(padres_token)
Num3 <- filter(padres_token, word == "0001f447")
Num4 <- filter(padres_token, word == "0001f4cc")
padres_token <- padres_token %>%
anti_join(Num3)
padres_token <- padres_token %>%
anti_join(Num4)
padres_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 1.5)
padres_token %>%
count(word, sort = TRUE) %>%
filter(n > 4) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
labs(
title= "Frecuencia de palabras de Padres Organizados",
subtitle = "Período del 9 al 16 de junio en Buenos Aireso",
x = "Palabras",
y = "Cantidad") +
coord_flip()
padres_token %>%
count(word, sort = TRUE) %>%
filter(n > 100) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
labs(
title= "Frecuencia de palabras de Padres Organizados",
subtitle = "Período del 9 al 16 de junio en Buenos Aireso",
x = "Palabras",
y = "Cantidad") +
coord_flip()
padres_token %>%
count(word, sort = TRUE) %>%
filter(n > 150) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
labs(
title= "Frecuencia de palabras de la cuenta Padres Organizados",
x = "Palabras",
y = "Cantidad") +
coord_flip()
#Ahora vamos a hacer el mismo procedmiento pero para el time line de la cuenta principal de Padres Organizados.
Padres <- read.csv("Padres.csv", encoding = "UTF-8")
padres_texto <- unique(Padres$text)
padres_texto <- padres_texto %>% as.data.frame() %>% rename(word=".")
padres_token <- padres_texto %>%
unnest_tokens(word, word)
padres_token <- padres_token %>%
anti_join(custom_stop_words)
tco2 <- filter(padres_token, word == "t.co")
padres_token <- padres_token %>%
anti_join(tco2)
https3 <- filter(padres_token, word == "https")
padres_token <- padres_token %>%
anti_join(https3)
u <- filter(padres_token, word == "u")
n <- filter(padres_token, word == "n")
fe0f <- filter(padres_token, word == "fe0f")
padres_token <- padres_token %>%
anti_join(u)
padres_token <- padres_token %>%
anti_join(n)
padres_token <- padres_token %>%
anti_join(fe0f)
s <- filter(padres_token, word == "s")
padres_token <- padres_token %>%
anti_join(s)
niã <- filter(padres_token, word == "niã")
padres_token <- padres_token %>%
anti_join(niã)
mã <- filter(padres_token, word == "mã")
padres_token <- padres_token %>%
anti_join(mã)
ã <- filter(padres_token, word == "ã")
padres_token <- padres_token %>%
anti_join(ã)
â <- filter(padres_token, word == "â")
padres_token <- padres_token %>%
anti_join(â)
estã <- filter(padres_token, word == "estã")
padres_token <- padres_token %>%
anti_join(estã)
Num3 <- filter(padres_token, word == "0001f447")
Num4 <- filter(padres_token, word == "0001f4cc")
Num5 <- filter(padres_token, word == "0001f56f")
padres_token <- padres_token %>%
anti_join(Num3)
padres_token <- padres_token %>%
anti_join(Num4)
padres_token <- padres_token %>%
anti_join(Num5)
padres_token %>%
count(word, sort=T) %>%
wordcloud2(color = "random-light", backgroundColor = "grey", size = 1.5)
padres_token %>%
count(word, sort = TRUE) %>%
filter(n > 150) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
labs(
title= "Frecuencia de palabras de la cuenta Padres Organizados",
x = "Palabras",
y = "Cantidad") +
coord_flip()
gc()
